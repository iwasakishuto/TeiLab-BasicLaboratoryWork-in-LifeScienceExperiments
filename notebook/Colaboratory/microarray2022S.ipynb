{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "microarray2022S.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNazQ/NmXsZGv9gv5TAX+7S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iwasakishuto/TeiLab-BasicLaboratoryWork-in-LifeScienceExperiments/blob/main/notebook/Colaboratory/microarray2022S.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeGmvlURRMrG"
      },
      "source": [
        "## マイクロアレイデータ解析 \\~2022 Spring Semester\\~\n",
        "\n",
        "- 程研HP: http://ui-tei.rnai.jp/\n",
        "- 実習wiki: http://ui-tei.rnai.jp/microarray/doku.php?id=%E7%A8%8B%E7%A0%94%E5%AE%9F%E7%BF%92:2022\n",
        "\n",
        "今回の実習では、**「マイクロアレイを用いた網羅的遺伝子発現解析」**というタイトルで、網羅的に遺伝子の発現を解析する手法であるマイクロアレイの「原理」「操作手順」「解析方法」について、\n",
        "\n",
        "- wet(実験)：siRNAを導入した細胞からRNAを抽出し、マイクロアレイを行う。\n",
        "- dry(解析)：全mRNAの変動量を、マイクロアレイデータの特徴を踏まえて解析する。\n",
        "\n",
        "の両側面から学んでいただきますが、このNotebookでは、**dry(解析)** パートに関して、プログラミング言語: [Python](https://www.python.org/)を使って実際に手を動かしながら学んでいきます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY1NoHEQU3oS"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFGCgNsfU3wr"
      },
      "source": [
        "### 0. 環境構築\n",
        "\n",
        "　それでは解析を始めていきましょう！！解析に必要なデータや、各種ツールを揃えていきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixmefk4KVUXe"
      },
      "source": [
        "! pip install \"git+https://github.com/iwasakishuto/TeiLab-BasicLaboratoryWork-in-LifeScienceExperiments.git\" --ignore-requires-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtb5fMQ4mGkB"
      },
      "source": [
        "ここで\n",
        "\n",
        "```\n",
        "ERROR: XXX has requirement YYY==<version> but you'll have YYY <version> which is incompatible.\n",
        "WARNING: The following packages were previously imported in this runtime\n",
        "```\n",
        "\n",
        "のようなエラーが出る分には問題ありません。以下のコマンドでエラーが出なければ準備はOKです！\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz62WFX1klGL"
      },
      "source": [
        "from teilab.question import ask\n",
        "\n",
        "ret = ask(\n",
        "    text=\"好きな言葉を入力してください。\", \n",
        "    username=\"あなたの名前\", \n",
        "    icon_emoji=\":grinning:\", \n",
        "    icon_url=None, \n",
        "    webhook_url=None,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFN3MwovpJ4g"
      },
      "source": [
        "### 1. データの準備\n",
        "\n",
        "　続いて、データの準備に取り掛かります。先ほどインストールしたパッケージを用いてデータのダウンロードを行います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V6UAoFQ25F3"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy.typing as npt\n",
        "from teilab.datasets import TeiLabDataSets\n",
        "from typing import List, Optional, Union\n",
        "\n",
        "dataset = TeiLabDataSets()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGRdKxKepnPw"
      },
      "source": [
        "password1 = \"microarray2022S\"\n",
        "path1 = dataset.get_data(password=password1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e6Wa1UXZDVB"
      },
      "source": [
        "password2 = \"microarray2021S\"\n",
        "path2 = dataset.get_data(password=password2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "password3 = \"\"\n",
        "path3 = dataset.get_data(password=password3)"
      ],
      "metadata": {
        "id": "XrCsIuagNKoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMqAsmJpqIX8"
      },
      "source": [
        "### 2. データの読み込み"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_xIE1eZrWfG"
      },
      "source": [
        "```python\n",
        "# 本来はこんな感じで読み込みをする。\n",
        "import os\n",
        "import pandas as pd\n",
        "from teilab.utils._path import DATA_DIR\n",
        "\n",
        "# Data (Password1)\n",
        "dirname1 = os.path.join(DATA_DIR, password1, \"実習解析用データ\")\n",
        "print(\"Data1 is @\", dirname1)\n",
        "print(sorted(os.listdir(dirname1)))\n",
        "df1_1_1 = pd.read_csv(os.path.join(dirname1, 'US91503671_253949442637_S01_GE1_105_Dec08_1_1.txt'), sep=\"\\t\", header=9)\n",
        "\n",
        "# Data (Password2)\n",
        "dirname2 = os.path.join(DATA_DIR, password2)\n",
        "print(\"Data2 is @\", dirname2)\n",
        "print(sorted(os.listdir(dirname2)))\n",
        "df2_1_1 = pd.read_csv(os.path.join(dirname2, 'SG19378659_257236339458_S001_GE1_1200_Jun14_1_1.txt'), sep=\"\\t\", header=9)\n",
        "````"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzwmCZautfFg"
      },
      "source": [
        "```sh\n",
        "# データの中身が知りたい方はこのコマンド\n",
        "! head -n20 {dataset.filePaths[0]}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G48IeZgMqPft"
      },
      "source": [
        "dataset.samples.show_groups()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.filePaths"
      ],
      "metadata": {
        "id": "S6RVQEs_ZXMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsZOHHtLrh4K"
      },
      "source": [
        "# 以下のコードで、楽に読み込みできる\n",
        "df1_1_1 = dataset.read_data(no=5)\n",
        "df1_1_1.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2_1_1 = dataset.read_data(no=0)\n",
        "df2_1_1.head(3)"
      ],
      "metadata": {
        "id": "AOIPgnCCNaAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86ME6Ns2vAtO"
      },
      "source": [
        "### 3. データの統合"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOgB7ByIus39"
      },
      "source": [
        "　それでは、昨日のExcelを使った解析と同様に、全サンプルのデータを一つにまとめていきましょう。\n",
        "\n",
        "　行番号とプローブ番号の対応関係は（同じタイミングの実験であれば）どのサンプルも同じであるので、サンプル $X$ のデータの隣にサンプル $Y$ のデータを concatenate すれば1枚のワークシート（DataFrame）にまとまります。\n",
        "\n",
        "　そこで、これを繰り返して、全サンプルの `gProcessedSignal` の値を1つのテーブルにまとめていきましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1 データの統合( `group_no=1` `US_XXX` で始まるデータ群 ) "
      ],
      "metadata": {
        "id": "th7MKNgUKMLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# このノートブックで扱うgroupのnumberリストを取得しておきます。\n",
        "group_numbers = dataset.samples.get_group_numbers(group_no=1)\n",
        "conditions = dataset.samples.Condition[group_numbers]\n",
        "for gn,cnd in zip(group_numbers, conditions):\n",
        "  print(gn, cnd)"
      ],
      "metadata": {
        "id": "GgoIR0agKR7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGHk_Mn5vJIL"
      },
      "source": [
        "##### 3.1.1 アノテーションデータの読み込み\n",
        "\n",
        "　まず、各プローブのアノテーションデータ（どういうプローブかの説明。以下のカラムの情報が大事）を取り出します。なお、このデータはサンプルに寄らないので、8つのサンプルのうち一つから一度だけ取り出します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl8cs3yRs3n8"
      },
      "source": [
        "USE_COLS_ANNO  = [\n",
        "    \"FeatureNum\", \"ControlType\", \"ProbeName\", \"GeneName\", \"SystematicName\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUNooMkL0T8U"
      },
      "source": [
        "|column name|description|\n",
        "|:-:|:-|\n",
        "|`FeatureNum`|スポットの番号|\n",
        "|`ControlType`|<ul><li>positive controlは `1`</li> <li>negative controlは `-1`</li><li>それ以外（解析で用いる）は `0`</li></ul>|\n",
        "|`ProbeName`|プローブ名|\n",
        "|`GeneName`|遺伝子名|\n",
        "|`SystematicName`|遺伝子名|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "386xeZHLvYJ2"
      },
      "source": [
        "df_anno = dataset.read_data(no=5, usecols=USE_COLS_ANNO)\n",
        "df_anno.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9mR89wHxFC8"
      },
      "source": [
        "##### 3.1.2 シグナル値の読み込み"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUdIErvWxTqV"
      },
      "source": [
        "続いて、各サンプルのシグナル強度( `gProcessedSignal` )のデータを取得します。\n",
        "\n",
        "なお、この時 `gIsWellAboveBG` が `0` のものは「（真の）シグナルがバックグラウンドのシグナルよりも低く、信頼できないデータである」ということを意味するため、取り除きます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvIHN9E0vt_I"
      },
      "source": [
        "USE_COLS_SYGNAL = [\n",
        "    \"gProcessedSignal\", \"gIsWellAboveBG\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcb0FnJl0ZUF"
      },
      "source": [
        "|column name|description|\n",
        "|:-:|:-|\n",
        "|`gProcessedSignal`|green(Cy-3)のシグナル強度（＝発現量）|\n",
        "|`gIsWellAboveBG`|（真の）シグナルがバックグラウンドのシグナルより十分高いか？（＝信頼できるデータか）|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syW9RfFjwfAf"
      },
      "source": [
        "df_combined = df_anno.copy(deep=True)\n",
        "index = set(df_combined.index)\n",
        "print(f\"データ数(before): {len(df_combined)}\")\n",
        "\n",
        "for gn,cnd in zip(group_numbers, conditions):\n",
        "  df_signal = dataset.read_data(no=gn, usecols=USE_COLS_SYGNAL)\n",
        "  index = index & set(df_signal[(df_signal.gIsWellAboveBG==1)].index)\n",
        "  df_combined = pd.concat([df_combined, df_signal[[\"gProcessedSignal\"]].rename(columns={\"gProcessedSignal\" : cnd})], axis=1)\n",
        "\n",
        "df_filtered_1 = df_combined.loc[list(index), :]\n",
        "print(f\"データ数(after) : {len(df_filtered_1)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxkM8pPQyWI3"
      },
      "source": [
        "　また、`ControlType` の値が $\\pm1$ のものはコントロールであるため、`0` のもののみ取り出します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-7trAS8ylsN"
      },
      "source": [
        "print(\"データ数(before):\", len(df_filtered_1))\n",
        "df_filtered_2 = df_filtered_1[df_filtered_1.ControlType == 0]\n",
        "print(\"データ数(after) :\", len(df_filtered_2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV5PQfm9ynhu"
      },
      "source": [
        "# インデックスを振り直す。\n",
        "df_filtered = df_filtered_2.reset_index(drop=True)\n",
        "df_filtered.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここまでで完成です🙆‍♂️"
      ],
      "metadata": {
        "id": "7gI5qm4tNRfE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2 データの統合( `group_no=0` `SG_XXX` で始まるデータ群 ) \n",
        "\n"
      ],
      "metadata": {
        "id": "mbTBy5zTK3ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# このノートブックで扱うgroupのnumberリストを取得しておきます。\n",
        "group_numbers = dataset.samples.get_group_numbers(group_no=0)\n",
        "conditions = dataset.samples.Condition[group_numbers]\n",
        "for gn,cnd in zip(group_numbers, conditions):\n",
        "  print(gn, cnd)"
      ],
      "metadata": {
        "id": "dU0JueIQK-i7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3.1.1 アノテーションデータの読み込み\n",
        "\n",
        "　まず、各プローブのアノテーションデータ（どういうプローブかの説明。以下のカラムの情報が大事）を取り出します。なお、このデータはサンプルに寄らないので、8つのサンプルのうち一つから一度だけ取り出します。"
      ],
      "metadata": {
        "id": "BBkKjC1aK5eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "USE_COLS_ANNO  = [\n",
        "    \"FeatureNum\", \"ControlType\", \"ProbeName\", \"SystematicName\"\n",
        "]"
      ],
      "metadata": {
        "id": "V22P8vAtLFXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "|column name|description|\n",
        "|:-:|:-|\n",
        "|`FeatureNum`|スポットの番号|\n",
        "|`ControlType`|<ul><li>positive controlは `1`</li> <li>negative controlは `-1`</li><li>それ以外（解析で用いる）は `0`</li></ul>|\n",
        "|`ProbeName`|プローブ名|\n",
        "|~`GeneName`~|~遺伝子名~|\n",
        "|`SystematicName`|遺伝子名|"
      ],
      "metadata": {
        "id": "uFFx87LlLK7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "※ こちらのデータには `GeneName` の情報がないので、対応表を用意して `GeneName` のデータを取得します。"
      ],
      "metadata": {
        "id": "O6ZFV4QELvFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown \"1NNQkfn7RVlmSud_5nMmBDqiwpv8LVgOc\" -O \"SG_correspondence_table.xlsx\""
      ],
      "metadata": {
        "id": "yVvLmksnLQLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_SGcorr = pd.read_excel(\"SG_correspondence_table.xlsx\", usecols=[\"FeatureNum\", \"GeneSymbol\", \"GeneName\"])\n",
        "df_SGcorr.head(3)"
      ],
      "metadata": {
        "id": "iQd2sCaMLnAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_anno = dataset.read_data(no=0, usecols=USE_COLS_ANNO)\n",
        "# 対応表のデータを結合します。\n",
        "df_anno = pd.merge(left=df_anno, right=df_SGcorr, on=\"FeatureNum\")\n",
        "df_anno.head(5)"
      ],
      "metadata": {
        "id": "p0_pnj2CLsXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ0uls_rM47z"
      },
      "source": [
        "##### 3.2.2 シグナル値の読み込み"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJklAg9KM478"
      },
      "source": [
        "続いて、各サンプルのシグナル強度( `gProcessedSignal` )のデータを取得します。\n",
        "\n",
        "なお、この時 `gIsWellAboveBG` が `0` のものは「（真の）シグナルがバックグラウンドのシグナルよりも低く、信頼できないデータである」ということを意味するため、取り除きます。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "USE_COLS_SYGNAL = [\n",
        "    \"gProcessedSignal\", \"gIsWellAboveBG\"\n",
        "]"
      ],
      "metadata": {
        "id": "SCHYtivqM9iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "|column name|description|\n",
        "|:-:|:-|\n",
        "|`gProcessedSignal`|green(Cy-3)のシグナル強度（＝発現量）|\n",
        "|`gIsWellAboveBG`|（真の）シグナルがバックグラウンドのシグナルより十分高いか？（＝信頼できるデータか）|"
      ],
      "metadata": {
        "id": "cbokYPlQM7Zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_combined = df_anno.copy(deep=True)\n",
        "index = set(df_combined.index)\n",
        "print(f\"データ数(before): {len(df_combined)}\")\n",
        "\n",
        "for gn,cnd in zip(group_numbers, conditions):\n",
        "  df_signal = dataset.read_data(no=gn, usecols=USE_COLS_SYGNAL)\n",
        "  index = index & set(df_signal[(df_signal.gIsWellAboveBG==1)].index)\n",
        "  df_combined = pd.concat([df_combined, df_signal[[\"gProcessedSignal\"]].rename(columns={\"gProcessedSignal\" : cnd})], axis=1)\n",
        "\n",
        "df_filtered_1 = df_combined.loc[list(index), :]\n",
        "print(f\"データ数(after) : {len(df_filtered_1)}\")"
      ],
      "metadata": {
        "id": "x9ZGN9ibNBzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "　また、`ControlType` の値が $\\pm1$ のものはコントロールであるため、`0` のもののみ取り出します。"
      ],
      "metadata": {
        "id": "QSALpfIRNHde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"データ数(before):\", len(df_filtered_1))\n",
        "df_filtered_2 = df_filtered_1[df_filtered_1.ControlType == 0]\n",
        "print(\"データ数(after) :\", len(df_filtered_2))"
      ],
      "metadata": {
        "id": "5dz0ycZLNI7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# インデックスを振り直す。\n",
        "df_filtered = df_filtered_2.reset_index(drop=True)\n",
        "df_filtered.head(5)"
      ],
      "metadata": {
        "id": "Cc8Lq7JuOKSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここまでで完成です🙆‍♂️"
      ],
      "metadata": {
        "id": "ViTKLxgGNU-y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.3 統合したデータの保存"
      ],
      "metadata": {
        "id": "Oilp3WysNXNS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8vZfoTjyvqt"
      },
      "source": [
        "```python\n",
        "# データをGoogleDriveに保存したい場合は、以下のコードを走らせてください。\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df_filtered.to_excel(\"microarray_filtered.xlsx\", index=False)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIsr41a8y0DI"
      },
      "source": [
        "### 4. データの前処理\n",
        "\n",
        "　無事にデータがダウンロードできたので、実験上のバイアス等を取り除くためにデータの前処理を行います。（ここでは、Summarizationのみを行います。）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87DsI6rfzyvB"
      },
      "source": [
        "df_filtered.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvSAFu1xzCoQ"
      },
      "source": [
        "# group_no=0, US_XXX のデータを読み込んでいる場合2つのmockデータを単純に平均化する。\n",
        "df_filtered[\"mock\"] = df_filtered[[\"mock(1)\", \"mock(2)\"]].mean(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# group_no=1, SG_XXX のデータを読み込んでいる場合\n",
        "# mockデータが一つなので、何もしない"
      ],
      "metadata": {
        "id": "4UbIJCebN-Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmApCjgfz9Vc"
      },
      "source": [
        "### 5. 解析 & 可視化\n",
        "\n",
        "ここでは、XYプロットとMAプロットを図示し、シグナル強度の分布を調べます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY_Me1dezb_-"
      },
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly import offline\n",
        "from plotly.subplots import make_subplots"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C6bWZyM0GOX"
      },
      "source": [
        "#### 5.1 X-Yプロット"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiIbWB1x08-7"
      },
      "source": [
        "- サンプル $X$ の `gProcessedSignal` の値を横軸\n",
        "- サンプル $Y$ の `gProcessedSignal` の値を縦軸\n",
        "\n",
        "にプロットしたものを **X-Yプロット** と呼びます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57C0cNqG0FJW"
      },
      "source": [
        "def XYplot(df: pd.DataFrame, x: str, y: str, hover_name: str = \"\", hover_data: str = \"\"):\n",
        "    fig = px.scatter(\n",
        "        df, x=x, y=y, hover_name=hover_name, hover_data=hover_data, title=f\"XY plot ({x} vs {y})\"\n",
        "    )\n",
        "    return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6dOqwD_1ARR"
      },
      "source": [
        "fig = XYplot(df=df_filtered, x=\"mock\", y=\"siVIM-270\", hover_name=\"GeneName\")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qASzdsG1y_u"
      },
      "source": [
        "> \"vimentin\" はどこにあるでしょうか？？"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkWyl71L15xr"
      },
      "source": [
        "#### 5.2 MAプロット\n",
        "\n",
        "- $log_2(Y/X)$ を縦軸 (Minus)\n",
        "- $log_{10}(XY)$ を横軸 (Average)\n",
        "\n",
        "にプロットしたものを **M-Aプロット** と呼びます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "611r4j-n114L"
      },
      "source": [
        "def MAplot(df: pd.DataFrame, control: str, target: str, hover_data: Optional[str] = None) -> go.Figure:\n",
        "    control_signals = df[control].values\n",
        "    target_signals = df[target].values\n",
        "    X = np.log10(control_signals * target_signals)\n",
        "    Y = np.log2(target_signals / control_signals)\n",
        "    if hover_data is None:\n",
        "        hover_data = []\n",
        "\n",
        "    fig = go.Figure(data=go.Scatter(x=X, y=Y, hovertext=df[hover_data].values, mode=\"markers\", marker_size=3))\n",
        "    fig.update_layout(\n",
        "        title=f\"MA plot ({control} vs {target})\",\n",
        "        xaxis_title=\"$log_{10}\" + f\"({target} * {control})$\",\n",
        "        yaxis_title=f\"$log_2{target}/{control}$\",\n",
        "    )\n",
        "    return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMZwXO_Q2w7a"
      },
      "source": [
        "fig = MAplot(df=df_filtered, control=\"mock\", target=\"siVIM-270\", hover_data=\"GeneName\")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZx86PUG2-8e"
      },
      "source": [
        "> - VIM はどこにあると予想できますか？？実際に確認してみてください！\n",
        "> - 縦軸が $0$ / $1$ / $-1$  とは何を意味しますか？？\n",
        "> - 横軸は何を意味しますか？？"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h7IIUF03JP0"
      },
      "source": [
        "### 6. 発展\n",
        "\n",
        "　ここからは、より良いデータ解析のためのいくつかの手法を紹介します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDfV-aGs3ARL"
      },
      "source": [
        "#### 6.1 データの正規化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhBBJiU74aNQ"
      },
      "source": [
        "from scipy.stats.mstats import gmean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM_OeXks3Zjo"
      },
      "source": [
        "# 度数曲線をプロットする。\n",
        "def plotDensities(\n",
        "    data, #: npt.NDArray[np.float64],\n",
        "    names, #: npt.NDArray[np.object0],\n",
        "    col: int = 1,\n",
        "    fig: Optional[go.Figure] = None,\n",
        "    title: str = \"\",\n",
        ") -> go.Figure:\n",
        "    n_samples, n_features = data.shape\n",
        "    if n_samples != len(names):\n",
        "        raise TypeError(f\"'data' and 'names' arrays must have the same shape, but got {n_samples}!={len(names)}\")\n",
        "    fig = fig or make_subplots(rows=1, cols=1)\n",
        "    for ith_data, name in zip(np.log2(data), names):\n",
        "        hist, bin_edges = np.histogram(a=ith_data, bins=100, density=True)\n",
        "        fig.add_trace(trace=go.Scatter(x=bin_edges[1:], y=hist, name=name, mode=\"lines\"), row=1, col=col)\n",
        "    fig.update_layout(\n",
        "        title=title,\n",
        "        xaxis_title=\"$log_2(\\\\text{gProcessedSignal})$\",\n",
        "        yaxis_title=\"Density\",\n",
        "    )\n",
        "    return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sOUdzKL3bJB"
      },
      "source": [
        "raw_data = df_filtered[conditions].T.values\n",
        "print(f\"raw_data.shape = {raw_data.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsUpZXik3u6a"
      },
      "source": [
        "fig = plotDensities(raw_data, names=conditions, title=\"raw data.\")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBbbe7zD4Un3"
      },
      "source": [
        "##### 6.1.1 75%tile\n",
        "\n",
        "最も単純な正規化手法\n",
        "\n",
        "1. 各サンプルごとに、発現量の小さい方から数えて順位75%に位置するものの値を求める。\n",
        "2. この75%tileの値は通常サンプルごとに異なるが、それらの（相乗）平均 `a` を求める。\n",
        "3. 各サンプルごとに、全プローブの値に 「 $a$ /そのサンプルにおける75%tileの値」をかける（つまり、全サンプルで75%tile値を $a$ に揃える。）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h9Qid4o4Xuo"
      },
      "source": [
        "def tile75_normalization(data): #: npt.NDArray[np.float64]) -> npt.NDArray[np.float64]:\n",
        "    percentiles = np.percentile(a=data, q=75, axis=1)\n",
        "    a = gmean(percentiles)\n",
        "    return data * (a / percentiles)[:, np.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNerym1s4lD1"
      },
      "source": [
        "tile75_data = tile75_normalization(raw_data)\n",
        "print(f\"tile75_data.shape = {tile75_data.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Buji2KXw4mjS"
      },
      "source": [
        "fig = plotDensities(tile75_data, names=conditions, title=\"75%tile\")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M93yNO4r4vGk"
      },
      "source": [
        "##### 6.1.2 quantile法\n",
        "\n",
        "1. 各サンプルごとに発現量の値を順番に並べ替え、各順位の値をそれぞれ同順位のシグナル値の相乗平均で置き換える。\n",
        "2. その結果、全サンプルで分布が同一になる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzIw6pxH41br"
      },
      "source": [
        "def quantile_normalization(data): #: npt.NDArray[np.float64]) -> npt.NDArray[np.float64]:\n",
        "    return gmean(a=np.sort(a=data, axis=1), axis=0)[np.argsort(np.argsort(data, axis=1), axis=1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4ncGGCU42dk"
      },
      "source": [
        "quantiled_data = quantile_normalization(raw_data)\n",
        "print(f\"quantiled_data.shape = {quantiled_data.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0uSQs8s43Li"
      },
      "source": [
        "fig = plotDensities(quantiled_data, names=conditions, title=\"quantile\")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHHh1m7k47c6"
      },
      "source": [
        "#### 6.1.3 正規化手法の比較\n",
        "\n",
        "各正規化処理後のデータを比較して見ましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sEKKXs-5GAD"
      },
      "source": [
        "fig = make_subplots(rows=1, cols=3)\n",
        "plotDensities(raw_data,       names=conditions, fig=fig, col=1)\n",
        "plotDensities(tile75_data,    names=conditions, fig=fig, col=2)\n",
        "plotDensities(quantiled_data, names=conditions, title=\"Comparison of normalization methods\", fig=fig, col=3)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcGlauLG5RCX"
      },
      "source": [
        "### 6.2 seedマッチする遺伝子群の累積度数を調べる\n",
        "\n",
        "入力した配列を3'UTRにもつ遺伝子（アクセッション番号）のリストを表示するページ（[seedmatch](http://atlas.RNAi.jp/seedmatch/)）を用いて、siRNAのガイド鎖のseed（`UGAACUC`）と相補的な配列（`GAGTTCA`）が3'UTRに存在する遺伝子を検索する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrjchYwx6Dxf"
      },
      "source": [
        "##### 6.2.1 seed領域で調べてみる。\n",
        "\n",
        "まずは、siRNAのガイド鎖のseed（UGAACUC）と相補的な配列（GAGTTCA）が3'UTRに存在する遺伝子の発現量が本当に下がっているのか調べて見ましょう。つまり、オフターゲット効果を検証する、ということです。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IEOvHpk5G1Z"
      },
      "source": [
        "! gdown \"18YAbR7CvoUZADGpi3u5yS1S8EZ8sF8wk\" -O \"seedmatch.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfuHzhM55Wcy"
      },
      "source": [
        "df_matched_mRNAs = pd.read_csv(\"seedmatch.txt\")\n",
        "df_matched_mRNAs.columns = [\"SystematicName\", \"NumHits\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-R7n5A0-5ZpZ"
      },
      "source": [
        "# seedmatchで検索したデータと紐付ける。\n",
        "df_is_matched = pd.merge(df_filtered, df_matched_mRNAs, on=\"SystematicName\", how=\"left\").fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpBuE7H65dCm"
      },
      "source": [
        "# 累積度数曲線を描くために、ソートする。\n",
        "df_is_matched[\"log2(RNA/mock)\"] = np.log2(df_is_matched[\"siVIM-270\"]/df_is_matched[\"mock\"])\n",
        "df_is_matched = df_is_matched.sort_values(by=\"log2(RNA/mock)\").reset_index(drop=False)\n",
        "df_is_matched.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8RvITEh52i8"
      },
      "source": [
        "def CFC_trace_create(data, name:str=\"\") -> go.Scatter:\n",
        "    \"\"\"Create a CFC(Cumulative Frequency Curve)\"\"\"\n",
        "    num_data = len(data)\n",
        "    trace = go.Scatter(x=data, y=[(i+1)/num_data for i in range(num_data)], mode=\"lines\", name=name)\n",
        "    return trace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahyJZYsy55lu"
      },
      "source": [
        "fig = {\n",
        "    \"data\":[\n",
        "        CFC_trace_create(data=df_is_matched[df_is_matched[\"NumHits\"]==0][\"log2(RNA/mock)\"].values, name=\"others\"),\n",
        "        CFC_trace_create(data=df_is_matched[df_is_matched[\"NumHits\"]!=0][\"log2(RNA/mock)\"].values, name=\"seed matched mRNAs\")\n",
        "    ],\n",
        "    \"layout\": go.Layout(title=\"The expression level(All vs seed matched mRNAs)\", xaxis_title=\"$log_2(RNA/mock)$\", yaxis_title=\"Cumulative frequency\")\n",
        "}\n",
        "offline.iplot(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwH3UXte58K6"
      },
      "source": [
        "##### 6.2.2 seedマッチで色々遊んでみる。\n",
        "\n",
        "　ここから先は、みなさんが興味を持った点について、思う存分データで遊んでいただく時間です。\n",
        "\n",
        "- マッチするシードの数（`NumHits`）って、多い方が抑制されてる？？\n",
        "- そもそもなんで2-8の7merでオフターゲット効果が起きるの？？\n",
        "  - 1-7や3-9は？？\n",
        "  - 6merや9merは？？\n",
        "  - Argonauteタンパク質と結合（loading）し、RISC(RNA induced silencing complex)を形成するが、構造的に…\n",
        "- 統計的に有意だと言える？？\n",
        "\n",
        "面白そうなことについては、積極的に調べて見てください！！\n",
        "\n",
        "※ 以下に、使えそうなツールを用意しておきました。ぜひ解析に役立ててください！！"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIhk_7W16AaK"
      },
      "source": [
        "from teilab.seedmatch import get_matched_mRNAs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKpmgDBy6u1J"
      },
      "source": [
        "df_matched_mRNAs = get_matched_mRNAs(\"GAGTTCA\")\n",
        "df_matched_mRNAs.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIg5j70O6xYI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}